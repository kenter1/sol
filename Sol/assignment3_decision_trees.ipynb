{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](mlcourse.ai) – Open Machine Learning Course \n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Anna Tarelina (@feuerengel). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment #3. Fall 2018\n",
    "## <center> Decision trees for classification and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this assignment, we will find out how a decision tree works in a regression task, then will build and tune classification decision trees for identifying heart diseases.\n",
    "Fill in the missing code in the cells marked \"You code here\" and answer the questions in the [web form](https://docs.google.com/forms/d/1hsrNFSiRsvgB27gMbXfQWpq8yzNhLZxuh_VSzRz7XhI).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A simple example of regression using decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the following one-dimensional regression problem. It is needed to build the function $a(x)$ to approximate original dependency $y = f(x)$ using mean-squared error $min \\sum_i {(a(x_i) - f(x_i))}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.linspace(-2, 2, 7)\n",
    "y = X ** 3\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make several steps to build the decision tree. Let's choose the symmetric thresholds equal to 0, 1.5 and -1.5 for partitioning. In the case of a regression task, the leaf outputs mean answer for all observations in this leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from tree of depth 0 that contains all train observations. How will predictions of this tree look like for $x \\in [-2, 2]$? Create the appropriate plot using a pen, paper and Python if it is needed (without using `sklearn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data according to the following condition $[x < 0]$. It gives us the tree of depth 1 with two leaves. Let's create a similar plot for predictions of this tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the decision tree algorythm the feature and the threshold for splitting are chosen by some criterion. The commonly used criterion for regression is variance: $$Q(X, j, t) = D(X) - \\dfrac{|X_l|}{|X|} D(X_l) - \\dfrac{|X_r|}{|X|} D(X_r),$$\n",
    "where $X$ are observations in this node, $X_l$ and $X_r$ are splits of sample $X$ for two parts by the following criterion $[x_j < t]$ (by $j$-th feature and threshold $t$), $|X|$, $|X_l|$, $|X_r|$ are sizes of approprite samples, and $D(X)$ is the variance of the answers in $X$:\n",
    "$$D(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}(y_j – \\dfrac{1}{|X|}\\sum_{x_i \\in X}y_i)^2,$$\n",
    "where $y_i = y(x_i)$ is the answer for $x_i$ observation. Feature $j$ and threshold $t$ are chosen to maximize the value of the functional $Q(X, j, t)$ for each split.\n",
    "\n",
    "In our case there's only ine feature so $Q$ depends on threshold $t$ (and answers in this node).\n",
    "\n",
    "Create the plot of the function $Q(X, t)$ in the root depending on the threshold value $t$ on the interval $[-1.9, 1.9]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.        , -2.37037037, -0.2962963 ,  0.        ,  0.2962963 ,\n",
       "        2.37037037,  8.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.        , -1.33333333, -0.66666667,  0.        ,  0.66666667,\n",
       "        1.33333333,  2.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)\n",
    "X\n",
    "y\n",
    "\n",
    "X[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.        , -1.33333333, -0.66666667,  0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yFunc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7b09bbbf5667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'yFunc' is not defined"
     ]
    }
   ],
   "source": [
    "np.sum(yFunc(X[4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yFunc(X):\n",
    "    return X ** 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def D(X):\n",
    "    return np.var(yFunc(X))\n",
    "    \n",
    "def D1(X,y):\n",
    "    XCardinal = X.size\n",
    "    return (1/XCardinal) * np.sum(np.power(y-(1/XCardinal)*np.sum(y),2))\n",
    "    \n",
    "D(X) == D1(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5124.897146668323"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Q(X,y,j,t):\n",
    "    for i in range(0,X.size):\n",
    "        if(X[i] > t):\n",
    "            break\n",
    "    Xl = X[:i]\n",
    "    Xr = X[i:]\n",
    "    \n",
    "    return D(yFunc(X)) - (Xl.size/X.size) * D(yFunc(Xl)) - (Xr.size/X.size)*D(yFunc(Xr))\n",
    "\n",
    "Q(X,y,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_var_criterion(X, y, t):\n",
    "    #  [xj<t]  (by  j -th feature and threshold  t )\n",
    "    for j in range(0,X.size):\n",
    "        if(X[j] > t):\n",
    "            break\n",
    "    Xl = X[:j]\n",
    "    Xr = X[j:]\n",
    "            \n",
    "        \n",
    "    return D(yFunc(X)) - (Xl.size/X.size)*D(yFunc(Xl)) - (Xr.size/X.size)*D(yFunc(Xr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11569.705588656789"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.linspace(-1.9, 1.9, 10)\n",
    "y = yFunc(X)\n",
    "\n",
    "regression_var_criterion(X, y, -1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5124.897146668323"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q(X,y,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 1.</font> Is the threshold value $t = 0$ optimal according to the variance criterion?**\n",
    "- Yes\n",
    "- No "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's make splitting in each of the leaves' nodes. In the left branch (where previous split was $x < 0$) using the criterion $[x < -1.5]$, in the right branch (where previous split was $x \\geqslant 0$) with the following criterion $[x < 1.5]$. It gives us the tree of depth 2 with 7 nodes and 4 leaves. Create the plot of these tree predictions for $x \\in [-2, 2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 2.</font> How many segments are there on the plot of tree predictions in the interval [-2, 2] (it is necessary to count only horizontal and lines)?**\n",
    "- 2\n",
    "- 3\n",
    "- 4\n",
    "- 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a decision tree for predicting heart deseases\n",
    "Let's read the data on heart deseases. The dataset can be downloaded from the course repo from [here](https://github.com/Yorko/mlcourse.ai/blob/master/data/mlbootcamp5_train.csv) by clicking on `Download` and then selecting `Save As` option.\n",
    "\n",
    "**Problem**\n",
    "\n",
    "Predict presence or absence of cardiovascular disease (CVD) using the patient examination results.\n",
    "\n",
    "**Data description**\n",
    "\n",
    "There are 3 types of input features:\n",
    "\n",
    "- *Objective*: factual information;\n",
    "- *Examination*: results of medical examination;\n",
    "- *Subjective*: information given by the patient.\n",
    "\n",
    "| Feature | Variable Type | Variable      | Value Type |\n",
    "|---------|--------------|---------------|------------|\n",
    "| Age | Objective Feature | age | int (days) |\n",
    "| Height | Objective Feature | height | int (cm) |\n",
    "| Weight | Objective Feature | weight | float (kg) |\n",
    "| Gender | Objective Feature | gender | categorical code |\n",
    "| Systolic blood pressure | Examination Feature | ap_hi | int |\n",
    "| Diastolic blood pressure | Examination Feature | ap_lo | int |\n",
    "| Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "| Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "| Smoking | Subjective Feature | smoke | binary |\n",
    "| Alcohol intake | Subjective Feature | alco | binary |\n",
    "| Physical activity | Subjective Feature | active | binary |\n",
    "| Presence or absence of cardiovascular disease | Target Variable | cardio | binary |\n",
    "\n",
    "All of the dataset values were collected at the moment of medical examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/mlbootcamp5_train.csv', \n",
    "                 index_col='id', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the features: create \"age in years\" (full age) and also create 3 binary features based on `cholesterol` and 3 more on `gluc`, where they are equal to 1, 2 or 3. This method is called dummy-encoding or One Hot Encoding (OHE). It is more convenient to use `pandas.get_dummmies.`. There is no need to use the original features `cholesterol` and `gluc` after encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'] / 365\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(df['cholesterol'], prefix='chol')\n",
    "dummy.head()\n",
    "df = df.drop(columns='cholesterol')\n",
    "\n",
    "df = pd.concat([df,dummy],axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(df['gluc'],prefix='gluc')\n",
    "dummy.head()\n",
    "df = df.drop(columns='gluc')\n",
    "\n",
    "df = pd.concat([df,dummy],axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cardio']\n",
    "y.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='cardio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and holdout parts in the proportion of 7/3 using `sklearn.model_selection.train_test_split` with `random_state=17`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(df.values, y, test_size=0.3,\n",
    "random_state=17)\n",
    "# X_train, X_valid, y_train, y_valid = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the decision tree on the dataset `(X_train, y_train)` with max depth equals to 3 and `random_state=17`. Plot this tree with `sklearn.tree.export_graphviz`, `dot` and `pydot`. You don't need to use quotes in the file names in order to make it work in a jupyter notebook. The commands starting from the exclamation mark are terminal commands that are usually run in terminal/command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeClassifier(max_depth = 3, random_state=17)\n",
    "decisionTree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Image\n",
    "from io import StringIO\n",
    "import pydotplus #pip install pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(decisionTree, feature_names= df.columns, \n",
    "                out_file=dot_data, filled=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(value=graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 3.</font> What 3 features are used to make predictions in the created decision tree?**\n",
    "- weight, height, gluc=3\n",
    "- smoke, age, gluc=3\n",
    "- age, weight, chol=3\n",
    "### age, ap_hi, chol=3 This is the correct Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for holdout data `(X_valid, y_valid)` with the trained decision tree. Calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = decisionTree.predict(X_holdout)\n",
    "predicted\n",
    "accuracy_score(y_holdout,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the depth of the tree using cross-validation on the dataset `(X_train, y_train)` in order to increase quality of the model. Use `GridSearchCV` with 5 folds. Fix `random_state=17` and change  `max_depth` from 2 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params = {'max_depth': list(range(2, 11))}\n",
    "\n",
    "tree_grid = GridSearchCV(decisionTree, tree_params, cv=5)\n",
    "\n",
    "tree_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the plot to show how mean accuracy is changing in regards to `max_depth` value on cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTestScores = tree_grid.cv_results_['mean_test_score']\n",
    "meanTestScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.arange(2,meanTestScores.size+2,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(x, meanTestScores);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best value of `max_depth` where the mean value of cross-validation quality metric reachs maximum. Also compute accuracy on holdout data. All these computations are possible to make using the trained instance of the class `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tree_grid.predict(X_holdout)\n",
    "predicted\n",
    "accuracy_score(y_holdout,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 4.</font> Is there a local maximum of accuracy on the built validation curve? Did `GridSearchCV` help to tune `max_depth` so that there's been at least 1% change in holdout accuracy?**\n",
    "(check out the expression (acc2 - acc1) / acc1 * 100%, where acc1 and acc2 are accuracies on holdout data before and after tuning `max_depth` with `GridSearchCV` respectively)?\n",
    "- yes, yes\n",
    "### yes, no Yes the graph shows a local maximum. We gained less than 1% benefit\n",
    "- no, yes\n",
    "- no, no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#age age∈[40,50),[50,55),[55,60),[60,65) Brackets 1,2,3,4\n",
    "df['age'] = df['age'].mask((df['age'] < 40), 0)\n",
    "df['age'] = df['age'].mask((df['age'] >= 40) & (df['age'] < 50), 1)\n",
    "df['age'] = df['age'].mask((df['age'] >= 50) & (df['age'] < 55), 2)\n",
    "df['age'] = df['age'].mask((df['age'] >= 55) & (df['age'] < 60), 3)\n",
    "df['age'] = df['age'].mask((df['age'] >= 60) & (df['age'] < 65), 4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age Brack Dummy encoding\n",
    "dummy = pd.get_dummies(df['age'], prefix='ageBracket')\n",
    "dummy = dummy.drop(columns='ageBracket_0.0')\n",
    "\n",
    "df = df.drop(columns='age')\n",
    "df = pd.concat([df,dummy],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#systolic blood pressure:  ap_hi∈[120,140),ap_hi∈[140,160),ap_hi∈[160,180),  (3 features)\n",
    "df['ap_hi'] = df['ap_hi'].mask((df['ap_hi'] >= 180) , 0)\n",
    "df['ap_hi'] = df['ap_hi'].mask((df['ap_hi'] < 120) , 0)\n",
    "df['ap_hi'] = df['ap_hi'].mask((df['ap_hi'] >= 120) & (df['ap_hi'] < 140), 1)\n",
    "df['ap_hi'] = df['ap_hi'].mask((df['ap_hi'] >= 140) & (df['ap_hi'] < 160), 2)\n",
    "df['ap_hi'] = df['ap_hi'].mask((df['ap_hi'] >= 160) & (df['ap_hi'] < 180), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#systolic blood pressure bracket Dummy encoding\n",
    "dummy = pd.get_dummies(df['ap_hi'], prefix='ap_hi')\n",
    "dummy = dummy.drop(columns='ap_hi_0')\n",
    "\n",
    "df = df.drop(columns='ap_hi')\n",
    "df = pd.concat([df,dummy],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gender from 1 and 2 into 0 and 1. It is better to rename it to male (0 – woman, 1 – man)\n",
    "df['gender'] = df['gender'].mask((df['gender'] == 1) , 0)\n",
    "df['gender'] = df['gender'].mask((df['gender'] == 2) , 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns='height')\n",
    "df = df.drop(columns='weight')\n",
    "df = df.drop(columns='ap_lo')\n",
    "df = df.drop(columns='active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(df.values, y, test_size=0.3,\n",
    "random_state=17)\n",
    "\n",
    "decisionTree = DecisionTreeClassifier(max_depth = 3, random_state=17)\n",
    "decisionTree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(decisionTree, feature_names= df.columns, \n",
    "                out_file=dot_data, filled=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(value=graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the SCORE table to estimate ten-year risk of fatal cardiovascular disease in Europe. [Source paper](https://bit.ly/2Op7eQc).\n",
    "\n",
    "<img src='../../img/SCORE2007-eng.png' width=70%>\n",
    "\n",
    "Create binary features according to this picture:\n",
    "- $age \\in [40,50), \\ldots age \\in [60,65) $ (4 features)\n",
    "- systolic blood pressure: $ap\\_hi \\in [120,140), ap\\_hi \\in [140,160), ap\\_hi \\in [160,180),$ (3 features)\n",
    "\n",
    "If the values of age or blood pressure don't fall into any of the intervals then all binary features will be equal to zero. Then we create decision tree with these features and additional ``smoke``, ``cholesterol``  and ``gender`` features. Transform the ``cholesterol`` to 3 binary features according to it's 3 unique values ( ``cholesterol``=1,  ``cholesterol``=2 and  ``cholesterol``=3). This method is called dummy-encoding or One Hot Encoding (OHE). Transform the ``gender`` from 1 and 2 into 0 and 1. It is better to rename it to ``male`` (0 – woman, 1 – man). In general, this is typically done with ``sklearn.preprocessing.LabelEncoder`` but here in case of only 2 unique values it's not necessary.\n",
    "\n",
    "Finally the decision tree is built using 12 binary features (without original features).\n",
    "\n",
    "Create a decision tree with the limitation `max_depth=3` and train it on the whole train data. Use the `DecisionTreeClassifier` class with fixed `random_state=17`, but all other arguments (except for `max_depth` and `random_state`) should be set by default.\n",
    "\n",
    "**<font color='red'>Question 5.</font> What binary feature is the most important for heart disease detection (it is placed in the root of the tree)?**\n",
    "- Systolic blood pressure from 160 to 180 (mmHg)\n",
    "- Gender male / female\n",
    "## Systolic blood pressure from 140 to 160 (mmHg) this one???\n",
    "- Age from 50 to 55 (years)\n",
    "- Smokes / doesn't smoke\n",
    "- Age from 60 to 65 (years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = decisionTree.predict(X_holdout)\n",
    "\n",
    "accuracy_score(y_holdout,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "name": "lesson4_part2_Decision_trees.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
